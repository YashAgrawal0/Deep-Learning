# -*- coding: utf-8 -*-
"""unet_iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vVSvy29mgl7XXhdahov-GwE39PzZntxP
"""

# from google.colab import drive
# drive.mount('content')

# !unzip content/My\ Drive/Sem6/DL/A3/data2.zip

import os
import random
import numpy as np
# import matplotlib.pyplot as plt

from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import *
# from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout
# from tensorflow.keras.layers.core import Lambda, RepeatVector, Reshape
# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose
# from tensorflow.keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D
# from tensorflow.keras.layers.merge import concatenate, add
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

input_folder = "/users/home/dlagroup5/wd/Assignment3/Task2_Segmentation/data_extract_sample"
# input_folder = ""
X_train = np.load(input_folder + "/x_train.npy")
Y_train = np.load(input_folder + "/y_train.npy")
# X_test = np.load(input_folder + "x_test.npy")
# Y_test = np.load(input_folder + "y_test.npy")
# X_train = np.rollaxis(X_train,3,1)
# X_test = np.rollaxis(X_test,3,1)
print(X_train.shape)
print(Y_train.shape)
# print(X_test.shape)
img_shape = X_train[0].shape
mask_shape = Y_train[0].shape
print(img_shape,mask_shape)
# Y_train = np.reshape(Y_train,(Y_train.shape[0],Y_train.shape[1]*Y_train.shape[2],2))
# Y_test = np.reshape(Y_test,(Y_test.shape[0],Y_test.shape[1]*Y_test.shape[2],2))

# X_train = X_train[:,:,:,]
# Y_train = Y_train[:,:,:,0:1]
X_train = X_train/255
Y_train = Y_train/255
print(X_train.shape)
print(Y_train.shape)

def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):
    """Function to add 2 convolutional layers with the parameters passed to it"""
    # first layer
    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), padding = 'same')(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    # second layer
    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), padding = 'same')(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    return x

def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):
    """Function to define the UNET Model"""
    # Contracting Path
    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    p1 = MaxPooling2D((2, 2))(c1)
    p1 = Dropout(dropout)(p1)
    
    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)
    p2 = MaxPooling2D((2, 2))(c2)
    p2 = Dropout(dropout)(p2)
    
    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
#     p3 = MaxPooling2D((2, 2))(c3)
#     p3 = Dropout(dropout)(p3)
    
#     c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
#     p4 = MaxPooling2D((2, 2))(c4)
#     p4 = Dropout(dropout)(p4)
    
#     c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)
    
    # Expansive Path
#     u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)
#     u6 = concatenate([u6, c4])
#     u6 = Dropout(dropout)(u6)
#     c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    
#     u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)
#     u7 = concatenate([u7, c3])
#     u7 = Dropout(dropout)(u7)
#     c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
    
    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c3)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)
    
    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)
    u9 = concatenate([u9, c1])
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    
    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c9)
    model = Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = Input((300,400,3), name='img')
model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)
model.compile(optimizer=Adam(), loss="binary_crossentropy", metrics=["accuracy"])
model.summary()

model.fit(X_train, Y_train, batch_size=10, epochs=1)

model.save_weights('/users/home/dlagroup5/wd/Assignment3/Task2_Segmentation/model_unet1.hdf5')


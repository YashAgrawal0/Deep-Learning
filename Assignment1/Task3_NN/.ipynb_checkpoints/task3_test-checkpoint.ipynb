{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importImages(batchSize):\n",
    "\n",
    "    image_array = []\n",
    "    \n",
    "    y_true = np.zeros((batchSize,96))\n",
    "    \n",
    "    \n",
    "    for m in range(batchSize):\n",
    "        folderNo = random.randint(0,95)\n",
    "        class_of_image = folderNo\n",
    "        \n",
    "        l = int(folderNo%2)\n",
    "        k = int(folderNo/2)%12\n",
    "        j = int(folderNo/24)%2\n",
    "        i = int(folderNo/48)%2\n",
    "\n",
    "        imageClass = str(i)+'_'+str(j)+'_'+str(k)+'_'+str(l)\n",
    "        \n",
    "        img = cv2.imread('../Task1_Images/img/'+imageClass+'/'+imageClass+'_'+str(random.randint(0,999))+'.jpg').flatten()\n",
    "#         img = img.flatten()\n",
    "        image_array.append(img)\n",
    "        y_true[m][class_of_image] = 1\n",
    "\n",
    "    \n",
    "    image_array = np.array(image_array)\n",
    "\n",
    "    return image_array, y_true\n",
    "\n",
    "# x,y = importImages(95,100)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 76800\n",
    "n_validation = 9600\n",
    "n_test = 9600\n",
    "\n",
    "\n",
    "\n",
    "n_input = 2352   # input layer (28x28 pixels)\n",
    "n_hidden1 = 1024 # 1st hidden layer\n",
    "n_hidden2 = 512 # 2nd hidden layer\n",
    "n_hidden3 = 128 # 3rd hidden layer\n",
    "n_output = 96   # output layer (0-9 digits)\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1e-4\n",
    "n_iterations = 768\n",
    "batch_size = 100\n",
    "dropout = 0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_output])\n",
    "keep_prob = tf.placeholder(tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1': tf.Variable(tf.truncated_normal([2352,1024], stddev=0.1)),\n",
    "    'w2': tf.Variable(tf.truncated_normal([1024,512], stddev=0.1)),\n",
    "    'w3': tf.Variable(tf.truncated_normal([512,128], stddev=0.1)),\n",
    "    'out': tf.Variable(tf.truncated_normal([128,96], stddev=0.1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
    "    'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
    "    'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "# layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
    "output_layer = tf.matmul(layer_3, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=output_layer))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def forward_pass(X,y_true):\n",
    "    H1 = tf.add(tf.matmul(weights['w0'],X,True),biases['b0'])\n",
    "    H1 = tf.nn.relu(H1)\n",
    "\n",
    "    H2 = tf.add(tf.matmul(tf.transpose(weights['w1']),H1),biases['b1'])\n",
    "    H2 = tf.nn.relu(H2)\n",
    "    \n",
    "    H3 = tf.add(tf.matmul(tf.transpose(weights['w2']),H2),biases['b2'])\n",
    "    H3 = tf.nn.relu(H3)\n",
    "    \n",
    "    Y_true = tf.convert_to_tensor(y_true,dtype=tf.float32)\n",
    "    Y_true = tf.reshape(y_true,[96,1])\n",
    "    \n",
    "    Y_CAP = tf.add(tf.matmul(tf.transpose(weights['w3']),H3),biases['b3'])\n",
    "    Y_CAP = tf.nn.relu(Y_CAP)\n",
    "    \n",
    "    return tf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print(train_images[0])\n",
    "def training():\n",
    "    sess = tf.Session()\n",
    "    for i in range(0,len(train_images)):\n",
    "        X = tf.convert_to_tensor(train_images[i],dtype=tf.float32)\n",
    "        X = tf.reshape(X,[2352,1])\n",
    "        X = tf.sigmoid(X)\n",
    "        val = forward_pass(X,Y_true_train[i])\n",
    "        print(sess.run(val))\n",
    "        \n",
    "training()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "('Iteration', '0', '\\t| Loss =', '4.738905', '\\t| Accuracy =', '0.05')\n"
     ]
    }
   ],
   "source": [
    "# train on mini batches\n",
    "folder_no = -1\n",
    "print(1)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    if i%8 ==0:\n",
    "        folder_no += 1\n",
    "        \n",
    "    batch_x, batch_y = importImages(batch_size)\n",
    "    batch_x = batch_x/255\n",
    "    sess.run(cross_entropy, feed_dict={X: batch_x, Y: batch_y, keep_prob:dropout})\n",
    "    print \"itr: \" + str(i)\n",
    "\n",
    "#     print((batch_x/256).tolist())\n",
    "    # print loss and accuracy (per minibatch)\n",
    "    if i%96==0:\n",
    "        minibatch_loss, minibatch_accuracy = sess.run([cross_entropy, accuracy], feed_dict={X: batch_x, Y: batch_y, keep_prob:1.0})\n",
    "        print(\"Iteration\", str(i), \"\\t| Loss =\", str(minibatch_loss), \"\\t| Accuracy =\", str(minibatch_accuracy))\n",
    "\n",
    "        \n",
    "x_test,y_true_test = importImages(200)\n",
    "test_accuracy = sess.run(accuracy, feed_dict={X: x_test, Y: y_true_test, keep_prob:1.0})\n",
    "print(\"\\nAccuracy on test set:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = []\n",
    "img = cv2.imread('check.jpg')\n",
    "img = img.flatten()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sess.run(tf.argmax(output_layer,1), feed_dict={X: [img]})\n",
    "pred = np.squeeze(prediction)\n",
    "\n",
    "l = int(pred%2)\n",
    "k = int(pred/2)%12\n",
    "j = int(pred/24)%2\n",
    "i = int(pred/48)%2\n",
    "\n",
    "print (\"Prediction for test image:\", i,j,k,l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
